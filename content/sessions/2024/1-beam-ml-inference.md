---
title: "Beam for Large-Scale, Accelerated ML Inference at Google"
slug: beam-ml-inference
speakers:
 - Uday Kalra
room: Mariposa Grove
time_start: 2024-09-04 09:10:00
time_end: 2024-09-04 9:40:00
track: Keynote
day: 1
gridarea: "2 / 2 / 3 / 5"
timeslot: 1
images:
 - /images/sessions/2024/beam=ml-inference.jpg 
---

Bulk Inference in Machine Learning (ML) refers to the challenge of how to organize and compute model predictions for a large pool of available input data with no latency requirements. JAX is an open-source computation library commonly used by both engineers and researchers for flexible, high-performant ML development. This talk will illustrate how teams at Google are using Beam to ergonomically design, orchestrate, and scale JAX Bulk Inference workloads across various accelerator platforms.
