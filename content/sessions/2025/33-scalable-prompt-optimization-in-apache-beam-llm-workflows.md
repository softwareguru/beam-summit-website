---
title: "Scalable Prompt Optimization in Apache Beam LLM Workflows"
slug: scalable-prompt-optimization-in-apache-beam-llm-workflows
speakers:
 - Tomi Ajakaiye
topics:
 - Scalability & Performance
 - Emerging trends
room: The Bandshell
time_start: 2025-07-09 12:30:00
time_end: 2025-07-09 12:55:00
track: 
day: 20252
gridarea: "9/2/10/4"
timeslot: 33
images: 

slides: 2025/scalable-prompt-optimization-in-apache-beam-llm-workflows.pdf
video: https://youtu.be/JDH_GabMZiI
---

As Large Language Models (LLMs) become integral to data pipelines, optimizing prompts at scale is critical for consistency, cost control, and performance. In this session, youâ€™ll learn how to embed prompt-tuning and dynamic prompt-generation into an LLM workflow that is executed as Apache Beam pipeline.