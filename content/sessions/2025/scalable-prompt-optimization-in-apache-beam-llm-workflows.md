---
title: "Scalable Prompt Optimization in Apache Beam LLM Workflows"
slug: scalable-prompt-optimization-in-apache-beam-llm-workflows
speakers:
 - Tomi Ajakaiye
topics:
 - Scalability & Performance
 - Emerging trends
room: Horizon Hall
time_start: 2025-07-09 12:30:00
time_end: 2025-07-09 12:55:00
track: 
day: 
timeslot: 
gridarea: 
images: 

slides:
video:
---

As Large Language Models (LLMs) become integral to data pipelines, optimizing prompts at scale is critical for consistency, cost control, and performance. In this session, youâ€™ll learn how to embed prompt-tuning and dynamic prompt-generation into an LLM workflow that is executed as Apache Beam pipeline.